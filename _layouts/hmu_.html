---
layout: page
---
<div id="hmu">
    <section class="bg"></section>
    <h1 class="title">{{ page.title }}</h1>
    <div class="wrapper">
    </div>

    <div align="center">
        <h1>Human Motion Unlearning</h1>
        <h2><i>arXiv preprint</i></h2>
        <h5 style="color:grey"> <i>Edoardo De Matteis, Matteo Migliarini, Alessio Sampieri, Indro Spinelli, Fabio Galasso
</i>
        </h5>
        <!-- <h5 style="color:grey"> <i>Sapienza University of Rome, Italy</i></h5> -->
    </div>

    <hr>
    <p align="center"><button type="button" class="btn btn-primary"><a href="#abstract">Abstract</a></button>
        <!-- <button type="button" class="btn btn-primary"><a href="#qualitative">Paper Presentation</a></button> -->
        <button type="button" class="btn btn-primary"><a href="https://arxiv.org/pdf/">Paper</a></button>
        <!-- <button type="button" class="btn btn-primary"><a href="#poster-and-slides">Poster and Slides</a></button> -->
        <!-- <button type="button" class="btn btn-primary"><a href="#talk">Talk</a></button> -->
        <button type="button" class="btn btn-primary"><a
                href="https://github.com/edodema/human-motion-unlearning">Code</a></button>
    
                <hr>

            </p>
    <p align="center">
        <img src="\assets\img\projects\hmu\teaser.png" width="700" height="600" alt="centered image" />
    </p>
    

    <hr>
    <h1 id="abstract">Abstract</h1>
    We introduce the task of human motion unlearning to prevent the synthesis of toxic animations while preserving the general text-to-motion generative performance. Unlearning toxic motions is challenging as those can be generated from explicit text prompts and from implicit toxic combinations of safe motions (e.g., ``kicking" is ``loading and swinging a leg").
    We propose the first motion unlearning benchmark by filtering toxic motions from the large and recent text-to-motion datasets of HumanML3D and Motion-X. We propose baselines, by adapting state-of-the-art image unlearning techniques to process spatio-temporal signals. Finally, we propose a novel motion unlearning model based on Latent Code Replacement, which we dub LCR. LCR is training-free and suitable to the discrete latent spaces of state-of-the-art text-to-motion diffusion models. LCR is simple and consistently outperforms baselines qualitatively and quantitatively.
</div>